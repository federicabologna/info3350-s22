{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3350/6350\n",
    "\n",
    "## Lecture 28: Wrap-up\n",
    "\n",
    "## To do\n",
    "\n",
    "* Today is the last class meeting\n",
    "    * No lecture on Wednesday, nor section on Friday\n",
    "* Exam/project due **Thursday, 5/19, at 11:59pm** via CMS\n",
    "    * If project (or non-default data for the exam), then submit data, too\n",
    "* My office hours and TA office hours continue through the exam period\n",
    "    * Check the calendar (for TAs) and reservation slots (for me); times and availability may shift\n",
    "    * NB. Grad TAs and I will be unavailable 5/17-19\n",
    "* Course evaluations are open\n",
    "    * We take these seriously\n",
    "    * Larger *n* is better than smaller *n*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### What we've covered\n",
    "\n",
    "Keep these in mind as you work on your final project and as you think about your future plans. We've come a long way!\n",
    "\n",
    "* Simple word counts, including dictionary-based sentiment analysis\n",
    "* Distance/similarity metrics (linear and angular)\n",
    "* Regression\n",
    "* Unsupervised learning (clustering)\n",
    "* Supervised learning (classification)\n",
    "* Feature engineering\n",
    "* Feature importance and explainable models\n",
    "* Statistical hypothesis testing\n",
    "* Applied natural language processing\n",
    "    * Notably, part of speech tagging, lemmatization, dependency parsing, named entity recognition, etc.\n",
    "* Topic models\n",
    "* Word embeddings\n",
    "* Neural language models, including transformer-based large language models\n",
    "* Social media data access and ethics\n",
    "\n",
    "At this point, if you were given a corpus of texts, you should be comfortable finding groups of similar documents, identifying and tracking thematic content over time, training models to sort the texts into known categories, constructing plausible models of narrative progression across many stories, extracting information about the characters, places, and other entities in the documents, engineering different features and representations for any of these tasks, and evaluating both the performance of your models and the statistical significance of your results.\n",
    "\n",
    "If I had to highlight one *methodological* theme shared across the semester, it has been *approaches to document similarity*.\n",
    "\n",
    "### What we might have covered, but didn't\n",
    "\n",
    "* Network analysis\n",
    "* Generative applications of large lanuage models (BERT, ELMo, RoBERTa, T5) and transfer learning\n",
    "    * Including \"few shot\" and \"zero shot\" learning\n",
    "\n",
    "Why not ...\n",
    "\n",
    "## Applications\n",
    "\n",
    "* Hip-hop lyrics and patterns of co-production\n",
    "* Emotional story arcs\n",
    "* Gendered language in novels\n",
    "* Qualitative changes to literary studes arising from quantitative methods\n",
    "* Literary genre detection, both supervised and unsupervised\n",
    "    * Both intriguing, but for different reasons\n",
    "* Finding themes and measuring polarity in political texts\n",
    "* How to find and distinguish character types in novels\n",
    "* Measuring and predicting narrative time\n",
    "* Extracting and mapping literary geography\n",
    "* Finding political influence in historical debates\n",
    "* Mapping gendered and racialized language in narratives of the US South\n",
    "* Detecting personas and measuring power in social media narratives\n",
    "    * Plus, applied ethics for contemporary pseudo-public datasets\n",
    "    \n",
    "### Shared issues and themes\n",
    "\n",
    "* Gender and other categories of **social identity**\n",
    "* **Genre**, broadly speaking\n",
    "* The effects of **scale**\n",
    "* Exploration to uncover **content** of corpora: topics, distinctive words, settings, etc.\n",
    "\n",
    "All of these are conditioned on a concept of textual analysis that says: **texts are symptomatic objects**. Societies don't speak to us directly, but we can learn what a society might have told us by examining the objects it produces.\n",
    "\n",
    "## Feedback\n",
    "\n",
    "* Which methods pieces did you like most or find most useful?\n",
    "    * And least?\n",
    "* Which readings were most enjoyable or useful?\n",
    "    * What could go if we had to make room for new ones?\n",
    "* Thoughts about the mechanics of the course?\n",
    "    * Ed as a forum\n",
    "    * Office hours (frequency, schedule, format)\n",
    "    * Reading responses: number, frequency, Canvas the right venue?\n",
    "    * Mon/Weds/Fri breakdown by subject/task\n",
    "        * Did you want more of one or another area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
